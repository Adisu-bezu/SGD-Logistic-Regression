# SGD-Logistic-Regression
This repository implements Stochastic Gradient Descent (SGD) for optimizing logistic regression. It includes a comparison of NumPy and PyTorch implementations, hyperparameter tuning, and alternative optimizers like SGD with Momentum and Adam. The project analyzes training performance, validation error, and convergence behavior.
